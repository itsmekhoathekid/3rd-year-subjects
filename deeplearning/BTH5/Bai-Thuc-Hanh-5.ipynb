{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BÀI THỰC HÀNH 4: KIẾN TRÚC TRANSFORMER - BÀI TOÁN PHÂN LOẠI VĂN BẢN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hướng dẫn nộp bài:</b>\n",
    "- Folder chứa toàn bộ source code, đặt tên là <b>\\<MSSV\\>.zip</b> với \\<MSSV\\> là MSSV của các bạn.\n",
    "- Nộp qua course, giảng viên sẽ tạo submission sau mỗi buổi học.\n",
    "\n",
    "Bộ dữ liệu sử dụng: UIT-ViOCD (link download: https://drive.google.com/drive/folders/1Lu9axyLkw7dMx80uLRgvCnZsmNzhJWAa?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 1: Xây dựng mô hình Transformer Encoder gồm 3 lớp theo mô tả trong nghiên cứu [Attention is all you need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 2: Xây dựng mô hình Transformer Encoder gồm 3 lớp theo mô tả trong nghiên cứu [Attention is all you need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf). Tuy nhiên sử dụng learnable positional embedding thay thế cho sinusoidal positional encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 3: Xây dựng mô hình Transformer Encoder gồm 3 lớp sử dụng lớp có sẵn của Pytorch (hoặc Tensorflow)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
